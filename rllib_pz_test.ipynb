{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ray\n",
    "import supersuit as ss\n",
    "from ray import tune\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv  # RLlib-PZ interface\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumo_rl\n",
    "from reward_functions import diff_wait_time\n",
    "\n",
    "def env_creator(args):\n",
    "    env_params = {\n",
    "        \"net_file\": os.path.join(\"nets\",\"RESCO\",\"grid4x4\",\"grid4x4.net.xml\"),\n",
    "        \"route_file\": os.path.join(\"nets\",\"RESCO\",\"grid4x4\",\"grid4x4_1.rou.xml\"),\n",
    "        \"num_seconds\": 3600,\n",
    "        \"reward_fn\": diff_wait_time,\n",
    "        \"sumo_seed\": 42,\n",
    "    }\n",
    "    env = sumo_rl.parallel_env(**env_params)\n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 11:33:57,679\tINFO worker.py:1625 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "ray.init()\n",
    "\n",
    "env_name = \"grid4x4\"\n",
    "\n",
    "register_env(env_name, lambda config: ParallelPettingZooEnv(env_creator(config)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = (\n",
    "    PPOConfig()\n",
    "    .environment(env=env_name)\n",
    "    .rollouts(num_rollout_workers=0, batch_mode=\"complete_episodes\")\n",
    "    .framework(framework=\"torch\")\n",
    "    .training(\n",
    "        gamma=0.99,\n",
    "        lr=2.5e-4,\n",
    "        lambda_=0.95,\n",
    "        sgd_minibatch_size=256,\n",
    "        num_sgd_iter=4,\n",
    "        vf_loss_coeff=1.0,\n",
    "        entropy_coeff=1e-3,\n",
    "        clip_param=0.1,\n",
    "        grad_clip=0.5,\n",
    "    )\n",
    "    .debugging(log_level=\"INFO\")\n",
    "    .resources(num_gpus=int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 12:07:44,030\tWARNING env.py:285 -- Your MultiAgentEnv <ParallelPettingZooEnv instance> does not have some or all of the needed base-class attributes! Make sure you call `super().__init__()` from within your MutiAgentEnv's constructor. This will raise an error in the future.\n",
      "2023-05-02 12:07:44,035\tINFO policy.py:1285 -- Policy (worker=local) running on CPU.\n",
      "2023-05-02 12:07:44,036\tINFO torch_policy_v2.py:110 -- Found 1 visible cuda devices.\n",
      "2023-05-02 12:07:44,041\tINFO util.py:118 -- Using connectors:\n",
      "2023-05-02 12:07:44,042\tINFO util.py:119 --     AgentConnectorPipeline\n",
      "        ObsPreprocessorConnector\n",
      "        StateBufferConnector\n",
      "        ViewRequirementAgentConnector\n",
      "2023-05-02 12:07:44,042\tINFO util.py:120 --     ActionConnectorPipeline\n",
      "        ConvertToNumpyConnector\n",
      "        NormalizeActionsConnector\n",
      "        ImmutableActionsConnector\n",
      "2023-05-02 12:07:44,043\tINFO rollout_worker.py:2000 -- Built policy map: <PolicyMap lru-caching-capacity=100 policy-IDs=['default_policy']>\n",
      "2023-05-02 12:07:44,043\tINFO rollout_worker.py:2001 -- Built preprocessor map: {'default_policy': None}\n",
      "2023-05-02 12:07:44,044\tINFO rollout_worker.py:761 -- Built filter map: defaultdict(<class 'ray.rllib.utils.filter.NoFilter'>, {})\n",
      "2023-05-02 12:07:44,045\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 12:08:00,843\tINFO rollout_worker.py:909 -- Generating sample batch of size 4000\n",
      "2023-05-02 12:09:19,946\tWARNING env_runner_v2.py:154 -- More than 11520 observations in 720 env steps for episode 391696027291684039 are buffered in the sampler. If this is more than you expected, check that that you set a horizon on your environment correctly and that it terminates at some point. Note: In multi-agent environments, `rollout_fragment_length` sets the batch size based on (across-agents) environment steps, not the steps of individual agents, which can result in unexpectedly large batches.Also, you may be waiting for your Env to terminate (batch_mode=`complete_episodes`). Make sure it does at some point.\n",
      "2023-05-02 12:11:57,251\tWARNING env_runner_v2.py:154 -- More than 11520 observations in 720 env steps for episode 686425610722139992 are buffered in the sampler. If this is more than you expected, check that that you set a horizon on your environment correctly and that it terminates at some point. Note: In multi-agent environments, `rollout_fragment_length` sets the batch size based on (across-agents) environment steps, not the steps of individual agents, which can result in unexpectedly large batches.Also, you may be waiting for your Env to terminate (batch_mode=`complete_episodes`). Make sure it does at some point.\n",
      "Exception ignored in: <function SumoEnvironment.__del__ at 0x000001BA2C127250>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\admin\\anaconda3\\envs\\marl\\lib\\site-packages\\sumo_rl\\environment\\env.py\", line 446, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\Users\\admin\\anaconda3\\envs\\marl\\lib\\site-packages\\sumo_rl\\environment\\env.py\", line 436, in close\n",
      "    traci.close()\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\main.py\", line 263, in close\n",
      "    _connections[\"\"].close(wait)\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 355, in close\n",
      "    self._sendCmd(tc.CMD_CLOSE, None, None)\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 189, in _sendCmd\n",
      "    return self._sendExact()\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 106, in _sendExact\n",
      "    raise TraCIException(err, prefix[1], _RESULTS[prefix[2]])\n",
      "KeyError: 21\n",
      "2023-05-02 12:14:11,913\tWARNING env_runner_v2.py:154 -- More than 11520 observations in 720 env steps for episode 270665924183041501 are buffered in the sampler. If this is more than you expected, check that that you set a horizon on your environment correctly and that it terminates at some point. Note: In multi-agent environments, `rollout_fragment_length` sets the batch size based on (across-agents) environment steps, not the steps of individual agents, which can result in unexpectedly large batches.Also, you may be waiting for your Env to terminate (batch_mode=`complete_episodes`). Make sure it does at some point.\n",
      "2023-05-02 12:15:18,077\tINFO rollout_worker.py:950 -- Completed sample batch:\n",
      "\n",
      "{ 'count': 4320,\n",
      "  'policy_batches': { 'default_policy': { 'action_dist_inputs': np.ndarray((69120, 8), dtype=float32, min=-0.005, max=0.007, mean=0.0),\n",
      "                                          'action_logp': np.ndarray((69120,), dtype=float32, min=-2.084, max=-2.074, mean=-2.079),\n",
      "                                          'actions': np.ndarray((69120,), dtype=int64, min=0.0, max=7.0, mean=3.492),\n",
      "                                          'advantages': np.ndarray((69120,), dtype=float32, min=-535.331, max=2019.548, mean=-0.545),\n",
      "                                          'agent_index': np.ndarray((69120,), dtype=int32, min=0.0, max=15.0, mean=7.5),\n",
      "                                          'eps_id': np.ndarray((69120,), dtype=int64, min=2.706659241830415e+17, max=9.611581254342465e+17, mean=6.514687525304192e+17),\n",
      "                                          'infos': np.ndarray((69120,), dtype=object, head={}),\n",
      "                                          'new_obs': np.ndarray((69120, 33), dtype=float32, min=0.0, max=1.0, mean=0.052),\n",
      "                                          'obs': np.ndarray((69120, 33), dtype=float32, min=0.0, max=1.0, mean=0.052),\n",
      "                                          'rewards': np.ndarray((69120,), dtype=float32, min=-125.0, max=852.0, mean=-0.042),\n",
      "                                          't': np.ndarray((69120,), dtype=int32, min=0.0, max=719.0, mean=359.5),\n",
      "                                          'terminateds': np.ndarray((69120,), dtype=bool, min=0.0, max=0.0, mean=0.0),\n",
      "                                          'truncateds': np.ndarray((69120,), dtype=bool, min=0.0, max=1.0, mean=0.001),\n",
      "                                          'unroll_id': np.ndarray((69120,), dtype=int32, min=400.0, max=575.0, mean=487.5),\n",
      "                                          'value_targets': np.ndarray((69120,), dtype=float32, min=-535.332, max=2019.552, mean=-0.543),\n",
      "                                          'vf_preds': np.ndarray((69120,), dtype=float32, min=-0.005, max=0.006, mean=0.001)}},\n",
      "  'type': 'MultiAgentBatch'}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 69120\n",
      "connector_metrics:\n",
      "  ObsPreprocessorConnector_ms: 0.06513198216756184\n",
      "  StateBufferConnector_ms: 0.0\n",
      "  ViewRequirementAgentConnector_ms: 0.6788134574890137\n",
      "counters:\n",
      "  num_agent_steps_sampled: 69120\n",
      "  num_agent_steps_trained: 69120\n",
      "  num_env_steps_sampled: 4320\n",
      "  num_env_steps_trained: 4320\n",
      "custom_metrics: {}\n",
      "date: 2023-05-02_12-15-25\n",
      "done: false\n",
      "episode_len_mean: 720.0\n",
      "episode_media: {}\n",
      "episode_reward_max: -246.0\n",
      "episode_reward_mean: -482.1666666666667\n",
      "episode_reward_min: -732.0\n",
      "episodes_this_iter: 6\n",
      "episodes_total: 6\n",
      "hostname: JM-M16\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 539.5\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.19999999999999998\n",
      "        cur_lr: 0.00025\n",
      "        entropy: 2.0776924362889044\n",
      "        entropy_coeff: 0.001\n",
      "        grad_gnorm: 0.426115154116242\n",
      "        kl: 0.0017535451632545152\n",
      "        policy_loss: -0.002954182497988869\n",
      "        total_loss: 9.377007239394718\n",
      "        vf_explained_var: -0.002420284461092066\n",
      "        vf_loss: 9.381688413355086\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 256.0\n",
      "      num_grad_updates_lifetime: 540.5\n",
      "  num_agent_steps_sampled: 69120\n",
      "  num_agent_steps_trained: 69120\n",
      "  num_env_steps_sampled: 4320\n",
      "  num_env_steps_trained: 4320\n",
      "iterations_since_restore: 1\n",
      "node_ip: 127.0.0.1\n",
      "num_agent_steps_sampled: 69120\n",
      "num_agent_steps_trained: 69120\n",
      "num_env_steps_sampled: 4320\n",
      "num_env_steps_sampled_this_iter: 4320\n",
      "num_env_steps_trained: 4320\n",
      "num_env_steps_trained_this_iter: 4320\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 0\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 4320\n",
      "perf:\n",
      "  cpu_util_percent: 1.1796324655436445\n",
      "  ram_util_percent: 42.41699846860643\n",
      "pid: 19532\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.6885713406443402\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 95.40613589808775\n",
      "  mean_inference_ms: 1.968029333854875\n",
      "  mean_raw_obs_processing_ms: 3.079875424293919\n",
      "sampler_results:\n",
      "  connector_metrics:\n",
      "    ObsPreprocessorConnector_ms: 0.06513198216756184\n",
      "    StateBufferConnector_ms: 0.0\n",
      "    ViewRequirementAgentConnector_ms: 0.6788134574890137\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 720.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -246.0\n",
      "  episode_reward_mean: -482.1666666666667\n",
      "  episode_reward_min: -732.0\n",
      "  episodes_this_iter: 6\n",
      "  hist_stats:\n",
      "    episode_lengths: [720, 720, 720, 720, 720, 720]\n",
      "    episode_reward: [-347.0, -314.0, -604.0, -650.0, -246.0, -732.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.6885713406443402\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 95.40613589808775\n",
      "    mean_inference_ms: 1.968029333854875\n",
      "    mean_raw_obs_processing_ms: 3.079875424293919\n",
      "time_since_restore: 444.96659445762634\n",
      "time_this_iter_s: 444.96659445762634\n",
      "time_total_s: 444.96659445762634\n",
      "timers:\n",
      "  learn_throughput: 558.786\n",
      "  learn_time_ms: 7731.047\n",
      "  load_throughput: 0.0\n",
      "  load_time_ms: 0.0\n",
      "  sample_time_ms: 437234.548\n",
      "  synch_weights_time_ms: 0.0\n",
      "  training_iteration_time_ms: 444965.595\n",
      "timestamp: 1683026125\n",
      "timesteps_total: 4320\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "result = algo.train()\n",
    "print(pretty_print(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(PPO pid=12976)\u001b[0m 2023-05-02 00:20:14,573\tWARNING algorithm_config.py:635 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 881, in ray._raylet.execute_task\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 821, in ray._raylet.execute_task.function_executor\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m   File \"c:\\Users\\admin\\anaconda3\\envs\\marl\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 670, in actor_method_executor\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m     return method(__ray_actor, *args, **kwargs)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m   File \"c:\\Users\\admin\\anaconda3\\envs\\marl\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 460, in _resume_span\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m     return method(self, *_args, **_kwargs)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m   File \"c:\\Users\\admin\\anaconda3\\envs\\marl\\lib\\site-packages\\ray\\rllib\\env\\wrappers\\pettingzoo_env.py\", line 169, in __init__\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m     self.env = env_creator(copy.deepcopy(self.env_context))\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m   File \"C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_21328\\2883675884.py\", line 5, in <lambda>\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m     self.par_env.reset()\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m   File \"c:\\Users\\admin\\anaconda3\\envs\\marl\\lib\\site-packages\\pettingzoo\\utils\\conversions.py\", line 126, in reset\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m     observations = super().reset(seed=seed, options=options)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m     res = self.env.reset(seed=seed, options=options)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m     self.aec_env.reset(seed=seed, return_info=return_info, options=options)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m TypeError: BaseWrapper.reset() got an unexpected keyword argument 'return_info'\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=11780)\u001b[0m 2023-05-02 00:20:00,542\tERROR worker.py:844 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=11780, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x0000022A8925B820>)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_pistonball_v6_b5f2c_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tune\u001b[39m.\u001b[39;49mrun(\n\u001b[0;32m      2\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPPO\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPPO\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      4\u001b[0m     stop\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mtimesteps_total\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m500\u001b[39;49m},\n\u001b[0;32m      5\u001b[0m     checkpoint_freq\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m     local_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m~/ray_results/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m env_name,\n\u001b[0;32m      7\u001b[0m     config\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mto_dict(),\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\marl\\lib\\site-packages\\ray\\tune\\tune.py:939\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue, _tuner_api)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[39mif\u001b[39;00m incomplete_trials:\n\u001b[0;32m    938\u001b[0m     \u001b[39mif\u001b[39;00m raise_on_failed_trial \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m experiment_interrupted_event\u001b[39m.\u001b[39mis_set():\n\u001b[1;32m--> 939\u001b[0m         \u001b[39mraise\u001b[39;00m TuneError(\u001b[39m\"\u001b[39m\u001b[39mTrials did not complete\u001b[39m\u001b[39m\"\u001b[39m, incomplete_trials)\n\u001b[0;32m    940\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    941\u001b[0m         logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mTrials did not complete: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_pistonball_v6_b5f2c_00000])"
     ]
    }
   ],
   "source": [
    "# tune.run(\n",
    "#     \"PPO\",\n",
    "#     name=\"PPO\",\n",
    "#     stop={\"timesteps_total\": 500},\n",
    "#     checkpoint_freq=10,\n",
    "#     local_dir=\"~/ray_results/\" + env_name,\n",
    "#     config=config.to_dict(),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
