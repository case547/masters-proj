{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecMonitor\n",
    "from sumo_rl import parallel_env\n",
    "import supersuit as ss\n",
    "\n",
    "from evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.utils import set_random_seed\n",
    "\n",
    "TEST_NUM = 4\n",
    "SEED = 23423  # default SUMO seed no.\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Environment and Instantiate Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward_functions import combined_reward\n",
    "\n",
    "csv_dir = os.path.join(\"outputs\",\"grid4x4\",f\"test_{TEST_NUM}\")\n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)\n",
    "\n",
    "env_params = {\n",
    "    \"net_file\": os.path.join(\"nets\",\"grid4x4\",\"grid4x4.net.xml\"),\n",
    "    \"route_file\": os.path.join(\"nets\",\"grid4x4\",\"grid4x4_1.rou.xml\"),\n",
    "    \"num_seconds\": 3600,\n",
    "    \"reward_fn\": combined_reward,\n",
    "    \"sumo_seed\": SEED,\n",
    "}\n",
    "congestion_reward = combined_reward.__defaults__[0].__name__\n",
    "alpha = combined_reward.__defaults__[1]  # congestion component coefficient\n",
    "\n",
    "env = parallel_env(**env_params)\n",
    "# Maybe add frame-stacking here\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "\n",
    "# Create env for evaluation\n",
    "eval_env = VecMonitor(env)\n",
    "\n",
    "# Create env for training\n",
    "train_env = ss.concat_vec_envs_v1(env, num_vec_envs=8, base_class=\"stable_baselines3\")\n",
    "train_env = VecMonitor(train_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from hyperparams import custom\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    train_env,\n",
    "    tensorboard_log=os.path.join(\"logs\",\"grid4x4\"),\n",
    "    verbose=1,\n",
    "    # seed=SEED,\n",
    "    **custom,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-245990.18501207232\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate untrained random agent\n",
    "csv_path = os.path.join(csv_dir, \"untrained.csv\")\n",
    "tb_log_dir = os.path.join(\"logs\",\"grid4x4\",\"eval_untrained\")\n",
    "\n",
    "reward_untrained, _ = evaluate(model, eval_env, csv_path, tb_log_dir, n_eval_episodes=1)\n",
    "\n",
    "# Change made to SB3 > common > vec_env > vec_monitor.py > VecMonitor\n",
    "# Line 76 - added extra item to self.venv.step_wait() return\n",
    "# obs, rewards, dones, infos --> obs, rewards, dones, _, infos\n",
    "\n",
    "print(reward_untrained)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_csv = pd.read_csv(os.path.join(csv_dir, \"untrained.csv\"))\n",
    "arrived_untrained = sum(untrained_csv.arrived_num)\n",
    "pm_untrained = sum(untrained_csv.tyre_pm)\n",
    "final_wait_untrained = untrained_csv.waiting_time.iat[-1]\n",
    "\n",
    "data = [TEST_NUM, congestion_reward, alpha, 0,\n",
    "        reward_untrained, arrived_untrained, pm_untrained, final_wait_untrained]\n",
    "\n",
    "with open(\"grid_results.csv\", \"a\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\grid4x4\\PPO_3\n",
      "-----------------------------------\n",
      "| rollout/           |            |\n",
      "|    ep_len_mean     | 720        |\n",
      "|    ep_rew_mean     | -10200.519 |\n",
      "| time/              |            |\n",
      "|    fps             | 179        |\n",
      "|    iterations      | 1          |\n",
      "|    time_elapsed    | 729        |\n",
      "|    total_timesteps | 131072     |\n",
      "-----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -10065.127   |\n",
      "| time/                   |              |\n",
      "|    fps                  | 174          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 1498         |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016639231 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 3.33e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 3.32e+04     |\n",
      "|    n_updates            | 4            |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    value_loss           | 6.4e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -9989.725    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 177          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 2219         |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013728967 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 5.24e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.79e+04     |\n",
      "|    n_updates            | 8            |\n",
      "|    policy_gradient_loss | -0.000978    |\n",
      "|    value_loss           | 9.19e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -9953.131    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 175          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 2987         |\n",
      "|    total_timesteps      | 524288       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013770956 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 1.36e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.39e+04     |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.000832    |\n",
      "|    value_loss           | 5.26e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -9879.375    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 171          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 3813         |\n",
      "|    total_timesteps      | 655360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012133765 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.06        |\n",
      "|    explained_variance   | 3.22e-06     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.13e+04     |\n",
      "|    n_updates            | 16           |\n",
      "|    policy_gradient_loss | -0.00082     |\n",
      "|    value_loss           | 8.57e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 720         |\n",
      "|    ep_rew_mean          | -9763.37    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 173         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4538        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001656947 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.05       |\n",
      "|    explained_variance   | 1.37e-06    |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 2.3e+04     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.000948   |\n",
      "|    value_loss           | 4.97e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -9785.97     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 174          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 5264         |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015846759 |\n",
      "|    clip_fraction        | 0.00756      |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.04        |\n",
      "|    explained_variance   | 5.36e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.75e+04     |\n",
      "|    n_updates            | 24           |\n",
      "|    policy_gradient_loss | -0.000723    |\n",
      "|    value_loss           | 6.09e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -9718.008    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 175          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 5969         |\n",
      "|    total_timesteps      | 1048576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015413581 |\n",
      "|    clip_fraction        | 0.0058       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | 2.38e-07     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 2.38e+04     |\n",
      "|    n_updates            | 28           |\n",
      "|    policy_gradient_loss | -0.000526    |\n",
      "|    value_loss           | 5.73e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x28640f46ca0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnNoModelImprovement\n",
    "\n",
    "# Separate env for eval callback\n",
    "callback_env = ss.concat_vec_envs_v1(env, num_vec_envs=1, base_class=\"stable_baselines3\")\n",
    "callback_env = VecMonitor(callback_env)\n",
    "\n",
    "stop_train_callback = StopTrainingOnNoModelImprovement(max_no_improvement_evals=3, min_evals=5, verbose=1)\n",
    "eval_callback = EvalCallback(callback_env, callback_after_eval=stop_train_callback, eval_freq=25000,\n",
    "                             best_model_save_path=os.path.join(\"saved_models\",f\"grid4x4_{TEST_NUM}\"))\n",
    "\n",
    "TRAIN_STEPS = 1e6\n",
    "model.learn(total_timesteps=TRAIN_STEPS, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-143693.29015433788\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate trained agent\n",
    "csv_path = os.path.join(csv_dir, \"trained.csv\")\n",
    "tb_log_dir = os.path.join(\"logs\",\"grid4x4\",f\"PPO_{TEST_NUM}\",\"eval_trained\")\n",
    "\n",
    "reward_trained, _ = evaluate(model, eval_env, csv_path, tb_log_dir, n_eval_episodes=1)\n",
    "\n",
    "print(reward_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs\\\\grid4x4\\\\PPO_3\\\\eval_untrained'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move untrained.csv into numbered directory\n",
    "import shutil\n",
    "\n",
    "original = os.path.join(\"logs\",\"grid4x4\",\"eval_untrained\")\n",
    "target = os.path.join(\"logs\",\"grid4x4\",f\"PPO_{TEST_NUM}\",\"eval_untrained\")\n",
    "\n",
    "shutil.move(original, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_csv = pd.read_csv(os.path.join(csv_dir, \"trained.csv\"))\n",
    "arrived_trained = sum(trained_csv.arrived_num)\n",
    "pm_trained = sum(trained_csv.tyre_pm)\n",
    "final_wait_trained = trained_csv.waiting_time.iat[-1]\n",
    "\n",
    "data = [TEST_NUM, congestion_reward, alpha, TRAIN_STEPS,\n",
    "        reward_trained, arrived_trained, pm_trained, final_wait_trained]\n",
    "\n",
    "with open(\"grid4x4_results.csv\", \"a\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(\"saved_models\",f\"PPO_grid4x4_{TEST_NUM}\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_params.update({\"use_gui\": True, \"render_mode\": \"human\"})\n",
    "render_env = parallel_env(**env_params)\n",
    "\n",
    "# Maybe add frame-stacking here\n",
    "render_env = ss.pettingzoo_env_to_vec_env_v1(render_env)\n",
    "render_env = VecMonitor(render_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "\n",
    "obs = render_env.reset()\n",
    "\n",
    "folder_path = os.path.join(\"renders\",\"grid4x4\",f\"test_{TEST_NUM}\")\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "max_time = render_env.unwrapped.par_env.unwrapped.env.sim_max_time\n",
    "delta_time = render_env.unwrapped.par_env.unwrapped.env.delta_time\n",
    "vid_length = int(max_time/delta_time)\n",
    "\n",
    "for i in range(vid_length):\n",
    "    actions, _ = model.predict(obs, deterministic=True)\n",
    "    obs, rewards, dones, infos = render_env.step(actions)\n",
    "\n",
    "    im = pyautogui.screenshot(\n",
    "        os.path.join(folder_path,f\"img{i}.jpg\"),\n",
    "        region=(0, 0, 2560, 1542)\n",
    "    )\n",
    "\n",
    "render_env.close()  # clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-y', '-r', '5', '-i', 'renders\\\\grid4x4\\\\test_3\\\\img%d.jpg', 'videos\\\\grid4x4_3.mp4'], returncode=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\", \"-r\", \"30\", \"-i\",\n",
    "    f\"renders\\\\grid4x4\\\\test_{TEST_NUM}\\\\img%d.jpg\",\n",
    "    f\"videos\\\\grid4x4_{TEST_NUM}.mp4\"\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "732c5edff638c91026cc37889b73c340773ecf599b6624077a4552d06a9ec22c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
