{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Grid4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecMonitor\n",
    "from sumo_rl import parallel_env\n",
    "import supersuit as ss\n",
    "\n",
    "from evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_NUM = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Environment and Instantiate Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reward_functions import diff_wait_time\n",
    "\n",
    "env_params = {\n",
    "    \"net_file\": os.path.join(\"nets\",\"RESCO\",\"grid4x4\",\"grid4x4.net.xml\"),\n",
    "    \"route_file\": os.path.join(\"nets\",\"RESCO\",\"grid4x4\",\"grid4x4_1.rou.xml\"),\n",
    "    \"num_seconds\": 3600,\n",
    "    \"reward_fn\": diff_wait_time,\n",
    "    \"sumo_seed\": 42,\n",
    "}\n",
    "env = parallel_env(**env_params)\n",
    "\n",
    "# Maybe add frame-stacking here\n",
    "env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "env = ss.concat_vec_envs_v1(env, num_vec_envs=2, num_cpus=1, base_class=\"stable_baselines3\")\n",
    "env = VecMonitor(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Using hyperparams from RESCO supplement/appendix Table 5\n",
    "# https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/f0935e4cd5920aa6c7c996a5ee53a70f-Abstract-round1.html\n",
    "\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    learning_rate=2.5e-4,\n",
    "    gamma=0.99,\n",
    "    ent_coef=1e-3,\n",
    "    max_grad_norm=0.5,\n",
    "    n_steps=1024,\n",
    "    batch_size=256,\n",
    "    n_epochs=4,\n",
    "    gae_lambda=0.95,\n",
    "    clip_range=0.1,\n",
    "    # vf_coef=1.0,\n",
    "    tensorboard_log=os.path.join(\"logs\",\"grid4x4\"),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-205261.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate untrained random agent\n",
    "csv_dir = os.path.join(\"outputs\",\"grid4x4\",f\"test_{TEST_NUM}\")\n",
    "if not os.path.exists(csv_dir):\n",
    "    os.makedirs(csv_dir)\n",
    "\n",
    "csv_path = os.path.join(csv_dir, \"untrained.csv\")\n",
    "tb_log_dir = os.path.join(\"logs\",\"grid4x4\",\"eval_untrained\")\n",
    "\n",
    "mean_reward_untrained, std_reward_untrained = evaluate(model, env, csv_path, tb_log_dir, n_eval_episodes=1)\n",
    "\n",
    "# Change made to SB3 > common > vec_env > vec_monitor.py > VecMonitor\n",
    "# Line 76 - added extra item to self.venv.step_wait() return\n",
    "# obs, rewards, dones, infos --> obs, rewards, dones, _, infos\n",
    "\n",
    "print(mean_reward_untrained)\n",
    "print(std_reward_untrained)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to logs\\grid4x4\\PPO_2\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 195   |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 167   |\n",
      "|    total_timesteps | 32768 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 190          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 344          |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016727817 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 1.13e-05     |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 9.65e+03     |\n",
      "|    n_updates            | 4            |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 6.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 192          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 509          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011110866 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.00615      |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 4.85e+03     |\n",
      "|    n_updates            | 8            |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    value_loss           | 1.04e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 191          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 685          |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012475243 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.0261       |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 12           |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    value_loss           | 5.04e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x138c9840fa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-80570.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate trained agent\n",
    "csv_path = os.path.join(csv_dir, \"trained.csv\")\n",
    "tb_log_dir = os.path.join(\"logs\",\"grid4x4\",f\"PPO_{TEST_NUM}\",\"eval_trained\")\n",
    "\n",
    "mean_reward_trained, std_reward_trained = evaluate(model, env, csv_path, tb_log_dir, n_eval_episodes=1)\n",
    "\n",
    "print(mean_reward_trained)\n",
    "print(std_reward_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs\\\\grid4x4\\\\PPO_1\\\\eval_untrained'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move untrained.csv into numbered directory\n",
    "import shutil\n",
    "\n",
    "original = os.path.join(\"logs\",\"grid4x4\",\"eval_untrained\")\n",
    "target = os.path.join(\"logs\",\"grid4x4\",f\"PPO_{TEST_NUM}\",\"eval_untrained\")\n",
    "\n",
    "shutil.move(original, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(\"saved_models\",f\"PPO_grid4x4_{TEST_NUM}\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "data = [env_params[\"net_file\"], TEST_NUM, env_params[\"reward_fn\"].__name__, mean_reward_untrained, mean_reward_trained]\n",
    "\n",
    "with open(\"test_results.csv\", \"a\", encoding=\"UTF8\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.read_csv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_params.update({\"use_gui\": True, \"render_mode\": \"human\"})\n",
    "render_env = parallel_env(**env_params)\n",
    "\n",
    "# Maybe add frame-stacking here\n",
    "render_env = ss.pettingzoo_env_to_vec_env_v1(render_env)\n",
    "render_env = VecMonitor(render_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "render() got an unexpected keyword argument 'mode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     actions, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(obs)\n\u001b[0;32m     15\u001b[0m     obs, rewards, dones, infos \u001b[39m=\u001b[39m render_env\u001b[39m.\u001b[39mstep(actions)\n\u001b[1;32m---> 16\u001b[0m     render_env\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m     18\u001b[0m     im \u001b[39m=\u001b[39m pyautogui\u001b[39m.\u001b[39mscreenshot(\n\u001b[0;32m     19\u001b[0m         os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(folder_path,\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     20\u001b[0m         region\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2560\u001b[39m, \u001b[39m1542\u001b[39m)\n\u001b[0;32m     21\u001b[0m     )\n\u001b[0;32m     23\u001b[0m render_env\u001b[39m.\u001b[39mclose()  \u001b[39m# clean up\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Justin Mak\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:329\u001b[0m, in \u001b[0;36mVecEnvWrapper.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[np\u001b[39m.\u001b[39mndarray]:\n\u001b[1;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvenv\u001b[39m.\u001b[39;49mrender(mode\u001b[39m=\u001b[39;49mmode)\n",
      "\u001b[1;31mTypeError\u001b[0m: render() got an unexpected keyword argument 'mode'"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "\n",
    "obs = render_env.reset()\n",
    "\n",
    "folder_path = os.path.join(\"renders\",\"grid4x4\",f\"test_{TEST_NUM}\")\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "max_time = env.unwrapped.par_env.unwrapped.env.sim_max_time\n",
    "delta_time = env.unwrapped.par_env.unwrapped.env.delta_time\n",
    "vid_length = round(max_time/delta_time)\n",
    "\n",
    "for i in range(vid_length):\n",
    "    actions, _ = model.predict(obs)\n",
    "    obs, rewards, dones, infos = render_env.step(actions)\n",
    "    render_env.render()\n",
    "\n",
    "    im = pyautogui.screenshot(\n",
    "        os.path.join(folder_path,f\"img{i}.jpg\"),\n",
    "        region=(0, 0, 2560, 1542)\n",
    "    )\n",
    "\n",
    "render_env.close()  # clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3200, 1800)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render_env.unwrapped.par_env.unwrapped.env.virtual_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\n",
    "    \"ffmpeg\", \"-y\", \"-r\", \"5\", \"-i\",\n",
    "    f\"renders\\\\grid4x4\\\\test_{TEST_NUM}\\\\img%d.jpg\",\n",
    "    f\"videos\\\\grid4x4_{TEST_NUM}.mp4\"\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "render_env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "732c5edff638c91026cc37889b73c340773ecf599b6624077a4552d06a9ec22c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
